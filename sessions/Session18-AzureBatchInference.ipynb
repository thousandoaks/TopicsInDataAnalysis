{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b14d777",
   "metadata": {},
   "source": [
    "# Creating a Batch Inferencing Service\n",
    "#### In previous labs, you used an Azure ML pipeline to automate the training and registration of a model, and you published a model as a web service for real-time inferencing (getting predictions from a model). Now you'll combine these two concepts to create a pipeline for batch inferencing. What does that mean? Well, imagine a health clinic takes patient measurements all day, saving the details for each patient in a separate file. Then overnight, the diabetes prediction model can be used to process all of the day's patient data as a batch, generating predictions that will be waiting the following morning so that the clinic can follow up with patients who are predicted to be at risk of diabetes. That's what you'll implement in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e8423",
   "metadata": {},
   "source": [
    "## Connect to Your Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c48b2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.38.0 to work with sessions18-20workspace\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e51ce6",
   "metadata": {},
   "source": [
    "## Train and Register a Model\n",
    "#### If you have completed the previous lab in this course, you will have registered many versions of the diabetes_model model, and you're ready to go.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4499dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf51118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "370cc0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: diabetes-training\n"
     ]
    }
   ],
   "source": [
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace = ws, name = \"diabetes-training\")\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a58a402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n"
     ]
    }
   ],
   "source": [
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/MicrosoftLearning/mslearn-dp100/main/data/diabetes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12fe2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21f0d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a decision tree model\n",
      "Accuracy: 0.8906666666666667\n",
      "AUC: 0.8788248171550822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c413ddbaa186>:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  run.log('Accuracy', np.float(acc))\n",
      "<ipython-input-6-c413ddbaa186>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  run.log('AUC', np.float(auc))\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0485c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7a6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c78d14",
   "metadata": {},
   "source": [
    "## Generate and Upload Batch Data\n",
    "#### Since we don't actually have a fully staffed clinic with patients from whom to get new data for this course, you'll generate a random sample from our diabetes CSV file and use those to test the pipeline. Then you'll upload that data to a datastore in the Azure Machine Learning workspace and register a dataset for it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029e9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore, Dataset\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2380214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceworkingdirectory - Default = False\n",
      "workspaceartifactstore - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceblobstore - Default = True\n"
     ]
    }
   ],
   "source": [
    "# Set default data store\n",
    "ws.set_default_datastore('workspaceblobstore')\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40634648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes data\n",
    "\n",
    "\n",
    "\n",
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/MicrosoftLearning/mslearn-dp100/main/data/diabetes2.csv')\n",
    "# Get a 100-item sample of the feature columns (not the diabetic label)\n",
    "sample = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].sample(n=100).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b8146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d336fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created!\n",
      "Saving files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files saved!\n",
      "Uploading files to datastore...\n",
      "Uploading an estimated of 100 files\n",
      "Uploading batch-data/1.csv\n",
      "Uploaded batch-data/1.csv, 1 files out of an estimated total of 100\n",
      "Uploading batch-data/10.csv\n",
      "Uploaded batch-data/10.csv, 2 files out of an estimated total of 100\n",
      "Uploading batch-data/100.csv\n",
      "Uploaded batch-data/100.csv, 3 files out of an estimated total of 100\n",
      "Uploading batch-data/11.csv\n",
      "Uploaded batch-data/11.csv, 4 files out of an estimated total of 100\n",
      "Uploading batch-data/13.csv\n",
      "Uploaded batch-data/13.csv, 5 files out of an estimated total of 100\n",
      "Uploading batch-data/14.csv\n",
      "Uploaded batch-data/14.csv, 6 files out of an estimated total of 100\n",
      "Uploading batch-data/15.csv\n",
      "Uploaded batch-data/15.csv, 7 files out of an estimated total of 100\n",
      "Uploading batch-data/16.csv\n",
      "Uploaded batch-data/16.csv, 8 files out of an estimated total of 100\n",
      "Uploading batch-data/17.csv\n",
      "Uploaded batch-data/17.csv, 9 files out of an estimated total of 100\n",
      "Uploading batch-data/18.csv\n",
      "Uploaded batch-data/18.csv, 10 files out of an estimated total of 100\n",
      "Uploading batch-data/19.csv\n",
      "Uploaded batch-data/19.csv, 11 files out of an estimated total of 100\n",
      "Uploading batch-data/2.csv\n",
      "Uploaded batch-data/2.csv, 12 files out of an estimated total of 100\n",
      "Uploading batch-data/20.csv\n",
      "Uploaded batch-data/20.csv, 13 files out of an estimated total of 100\n",
      "Uploading batch-data/21.csv\n",
      "Uploaded batch-data/21.csv, 14 files out of an estimated total of 100\n",
      "Uploading batch-data/22.csv\n",
      "Uploaded batch-data/22.csv, 15 files out of an estimated total of 100\n",
      "Uploading batch-data/23.csv\n",
      "Uploaded batch-data/23.csv, 16 files out of an estimated total of 100\n",
      "Uploading batch-data/24.csv\n",
      "Uploaded batch-data/24.csv, 17 files out of an estimated total of 100\n",
      "Uploading batch-data/25.csv\n",
      "Uploaded batch-data/25.csv, 18 files out of an estimated total of 100\n",
      "Uploading batch-data/26.csv\n",
      "Uploaded batch-data/26.csv, 19 files out of an estimated total of 100\n",
      "Uploading batch-data/27.csv\n",
      "Uploaded batch-data/27.csv, 20 files out of an estimated total of 100\n",
      "Uploading batch-data/28.csv\n",
      "Uploaded batch-data/28.csv, 21 files out of an estimated total of 100\n",
      "Uploading batch-data/29.csv\n",
      "Uploaded batch-data/29.csv, 22 files out of an estimated total of 100\n",
      "Uploading batch-data/3.csv\n",
      "Uploaded batch-data/3.csv, 23 files out of an estimated total of 100\n",
      "Uploading batch-data/30.csv\n",
      "Uploaded batch-data/30.csv, 24 files out of an estimated total of 100\n",
      "Uploading batch-data/31.csv\n",
      "Uploaded batch-data/31.csv, 25 files out of an estimated total of 100\n",
      "Uploading batch-data/32.csv\n",
      "Uploaded batch-data/32.csv, 26 files out of an estimated total of 100\n",
      "Uploading batch-data/33.csv\n",
      "Uploaded batch-data/33.csv, 27 files out of an estimated total of 100\n",
      "Uploading batch-data/34.csv\n",
      "Uploaded batch-data/34.csv, 28 files out of an estimated total of 100\n",
      "Uploading batch-data/35.csv\n",
      "Uploaded batch-data/35.csv, 29 files out of an estimated total of 100\n",
      "Uploading batch-data/36.csv\n",
      "Uploaded batch-data/36.csv, 30 files out of an estimated total of 100\n",
      "Uploading batch-data/37.csv\n",
      "Uploaded batch-data/37.csv, 31 files out of an estimated total of 100\n",
      "Uploading batch-data/38.csv\n",
      "Uploaded batch-data/38.csv, 32 files out of an estimated total of 100\n",
      "Uploading batch-data/39.csv\n",
      "Uploaded batch-data/39.csv, 33 files out of an estimated total of 100\n",
      "Uploading batch-data/4.csv\n",
      "Uploaded batch-data/4.csv, 34 files out of an estimated total of 100\n",
      "Uploading batch-data/40.csv\n",
      "Uploaded batch-data/40.csv, 35 files out of an estimated total of 100\n",
      "Uploading batch-data/41.csv\n",
      "Uploaded batch-data/41.csv, 36 files out of an estimated total of 100\n",
      "Uploading batch-data/42.csv\n",
      "Uploaded batch-data/42.csv, 37 files out of an estimated total of 100\n",
      "Uploading batch-data/43.csv\n",
      "Uploaded batch-data/43.csv, 38 files out of an estimated total of 100\n",
      "Uploading batch-data/44.csv\n",
      "Uploaded batch-data/44.csv, 39 files out of an estimated total of 100\n",
      "Uploading batch-data/45.csv\n",
      "Uploaded batch-data/45.csv, 40 files out of an estimated total of 100\n",
      "Uploading batch-data/46.csv\n",
      "Uploaded batch-data/46.csv, 41 files out of an estimated total of 100\n",
      "Uploading batch-data/47.csv\n",
      "Uploaded batch-data/47.csv, 42 files out of an estimated total of 100\n",
      "Uploading batch-data/48.csv\n",
      "Uploaded batch-data/48.csv, 43 files out of an estimated total of 100\n",
      "Uploading batch-data/49.csv\n",
      "Uploaded batch-data/49.csv, 44 files out of an estimated total of 100\n",
      "Uploading batch-data/5.csv\n",
      "Uploaded batch-data/5.csv, 45 files out of an estimated total of 100\n",
      "Uploading batch-data/12.csv\n",
      "Uploaded batch-data/12.csv, 46 files out of an estimated total of 100\n",
      "Uploading batch-data/50.csv\n",
      "Uploaded batch-data/50.csv, 47 files out of an estimated total of 100\n",
      "Uploading batch-data/51.csv\n",
      "Uploaded batch-data/51.csv, 48 files out of an estimated total of 100\n",
      "Uploading batch-data/52.csv\n",
      "Uploaded batch-data/52.csv, 49 files out of an estimated total of 100\n",
      "Uploading batch-data/53.csv\n",
      "Uploaded batch-data/53.csv, 50 files out of an estimated total of 100\n",
      "Uploading batch-data/54.csv\n",
      "Uploaded batch-data/54.csv, 51 files out of an estimated total of 100\n",
      "Uploading batch-data/55.csv\n",
      "Uploaded batch-data/55.csv, 52 files out of an estimated total of 100\n",
      "Uploading batch-data/56.csv\n",
      "Uploaded batch-data/56.csv, 53 files out of an estimated total of 100\n",
      "Uploading batch-data/57.csv\n",
      "Uploaded batch-data/57.csv, 54 files out of an estimated total of 100\n",
      "Uploading batch-data/58.csv\n",
      "Uploaded batch-data/58.csv, 55 files out of an estimated total of 100\n",
      "Uploading batch-data/59.csv\n",
      "Uploaded batch-data/59.csv, 56 files out of an estimated total of 100\n",
      "Uploading batch-data/6.csv\n",
      "Uploaded batch-data/6.csv, 57 files out of an estimated total of 100\n",
      "Uploading batch-data/60.csv\n",
      "Uploaded batch-data/60.csv, 58 files out of an estimated total of 100\n",
      "Uploading batch-data/61.csv\n",
      "Uploaded batch-data/61.csv, 59 files out of an estimated total of 100\n",
      "Uploading batch-data/62.csv\n",
      "Uploaded batch-data/62.csv, 60 files out of an estimated total of 100\n",
      "Uploading batch-data/63.csv\n",
      "Uploaded batch-data/63.csv, 61 files out of an estimated total of 100\n",
      "Uploading batch-data/64.csv\n",
      "Uploaded batch-data/64.csv, 62 files out of an estimated total of 100\n",
      "Uploading batch-data/65.csv\n",
      "Uploaded batch-data/65.csv, 63 files out of an estimated total of 100\n",
      "Uploading batch-data/66.csv\n",
      "Uploaded batch-data/66.csv, 64 files out of an estimated total of 100\n",
      "Uploading batch-data/67.csv\n",
      "Uploaded batch-data/67.csv, 65 files out of an estimated total of 100\n",
      "Uploading batch-data/68.csv\n",
      "Uploaded batch-data/68.csv, 66 files out of an estimated total of 100\n",
      "Uploading batch-data/69.csv\n",
      "Uploaded batch-data/69.csv, 67 files out of an estimated total of 100\n",
      "Uploading batch-data/7.csv\n",
      "Uploaded batch-data/7.csv, 68 files out of an estimated total of 100\n",
      "Uploading batch-data/70.csv\n",
      "Uploaded batch-data/70.csv, 69 files out of an estimated total of 100\n",
      "Uploading batch-data/71.csv\n",
      "Uploaded batch-data/71.csv, 70 files out of an estimated total of 100\n",
      "Uploading batch-data/72.csv\n",
      "Uploaded batch-data/72.csv, 71 files out of an estimated total of 100\n",
      "Uploading batch-data/73.csv\n",
      "Uploaded batch-data/73.csv, 72 files out of an estimated total of 100\n",
      "Uploading batch-data/74.csv\n",
      "Uploaded batch-data/74.csv, 73 files out of an estimated total of 100\n",
      "Uploading batch-data/76.csv\n",
      "Uploaded batch-data/76.csv, 74 files out of an estimated total of 100\n",
      "Uploading batch-data/77.csv\n",
      "Uploaded batch-data/77.csv, 75 files out of an estimated total of 100\n",
      "Uploading batch-data/78.csv\n",
      "Uploaded batch-data/78.csv, 76 files out of an estimated total of 100\n",
      "Uploading batch-data/79.csv\n",
      "Uploaded batch-data/79.csv, 77 files out of an estimated total of 100\n",
      "Uploading batch-data/8.csv\n",
      "Uploaded batch-data/8.csv, 78 files out of an estimated total of 100\n",
      "Uploading batch-data/80.csv\n",
      "Uploaded batch-data/80.csv, 79 files out of an estimated total of 100\n",
      "Uploading batch-data/81.csv\n",
      "Uploaded batch-data/81.csv, 80 files out of an estimated total of 100\n",
      "Uploading batch-data/75.csv\n",
      "Uploaded batch-data/75.csv, 81 files out of an estimated total of 100\n",
      "Uploading batch-data/82.csv\n",
      "Uploaded batch-data/82.csv, 82 files out of an estimated total of 100\n",
      "Uploading batch-data/83.csv\n",
      "Uploaded batch-data/83.csv, 83 files out of an estimated total of 100\n",
      "Uploading batch-data/84.csv\n",
      "Uploaded batch-data/84.csv, 84 files out of an estimated total of 100\n",
      "Uploading batch-data/85.csv\n",
      "Uploaded batch-data/85.csv, 85 files out of an estimated total of 100\n",
      "Uploading batch-data/86.csv\n",
      "Uploaded batch-data/86.csv, 86 files out of an estimated total of 100\n",
      "Uploading batch-data/87.csv\n",
      "Uploaded batch-data/87.csv, 87 files out of an estimated total of 100\n",
      "Uploading batch-data/88.csv\n",
      "Uploaded batch-data/88.csv, 88 files out of an estimated total of 100\n",
      "Uploading batch-data/89.csv\n",
      "Uploaded batch-data/89.csv, 89 files out of an estimated total of 100\n",
      "Uploading batch-data/9.csv\n",
      "Uploaded batch-data/9.csv, 90 files out of an estimated total of 100\n",
      "Uploading batch-data/90.csv\n",
      "Uploaded batch-data/90.csv, 91 files out of an estimated total of 100\n",
      "Uploading batch-data/91.csv\n",
      "Uploaded batch-data/91.csv, 92 files out of an estimated total of 100\n",
      "Uploading batch-data/92.csv\n",
      "Uploaded batch-data/92.csv, 93 files out of an estimated total of 100\n",
      "Uploading batch-data/93.csv\n",
      "Uploaded batch-data/93.csv, 94 files out of an estimated total of 100\n",
      "Uploading batch-data/94.csv\n",
      "Uploaded batch-data/94.csv, 95 files out of an estimated total of 100\n",
      "Uploading batch-data/95.csv\n",
      "Uploaded batch-data/95.csv, 96 files out of an estimated total of 100\n",
      "Uploading batch-data/96.csv\n",
      "Uploaded batch-data/96.csv, 97 files out of an estimated total of 100\n",
      "Uploading batch-data/97.csv\n",
      "Uploaded batch-data/97.csv, 98 files out of an estimated total of 100\n",
      "Uploading batch-data/98.csv\n",
      "Uploaded batch-data/98.csv, 99 files out of an estimated total of 100\n",
      "Uploading batch-data/99.csv\n",
      "Uploaded batch-data/99.csv, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a folder\n",
    "batch_folder = './batch-data'\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "print(\"Folder created!\")\n",
    "\n",
    "# Save each sample as a separate file\n",
    "print(\"Saving files...\")\n",
    "for i in range(100):\n",
    "    fname = str(i+1) + '.csv'\n",
    "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\n",
    "print(\"files saved!\")\n",
    "\n",
    "# Upload the files to the default datastore\n",
    "print(\"Uploading files to datastore...\")\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\n",
    "\n",
    "# Register a dataset for the input data\n",
    "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\n",
    "try:\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \n",
    "                                             name='batch-data',\n",
    "                                             description='batch data',\n",
    "                                             create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a8611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
